{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e0ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, stem_text, preprocess_string\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_json(df):\n",
    "    infinite_defaultdict = lambda: defaultdict(infinite_defaultdict)\n",
    "    split_on_bar_without_empty_strings = lambda x: [y.strip() for y in x.split(\"|\") if y.strip() != \"\"]\n",
    "    json_data = []\n",
    "    for row in df.itertuples():\n",
    "        d = infinite_defaultdict()\n",
    "        d[\"_gene_id\"] = row._1\n",
    "        d[\"species_code\"] = row.species_code\n",
    "        d[\"species_name\"] = row.species_name\n",
    "        d[\"unique_gene_identifiers\"] = split_on_bar_without_empty_strings(row.unique_gene_identifiers)\n",
    "        d[\"other_gene_identifiers\"] = split_on_bar_without_empty_strings(row.other_gene_identifiers)\n",
    "        d[\"gene_models\"] = split_on_bar_without_empty_strings(row.gene_models)\n",
    "        d[\"text_unprocessed\"] = row.text_unprocessed\n",
    "        d[\"text_tokenized_sents\"] = row.text_tokenized_sents\n",
    "        d[\"text_tokenized_words\"] = row.text_tokenized_words\n",
    "        d[\"text_tokenized_stems\"] = row.text_tokenized_stems\n",
    "        d[\"annotations\"] = split_on_bar_without_empty_strings(row.annotations)\n",
    "        d[\"annotations_nc\"] = split_on_bar_without_empty_strings(row.annotations_nc)\n",
    "        d[\"reference_name\"] = row.reference_name\n",
    "        d[\"reference_file\"] = row.reference_file\n",
    "        d[\"reference_link\"] = row.reference_link\n",
    "        json_data.append(d)\n",
    "    return(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fdde90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_string(text, char_limit):\n",
    "    truncated_text = text[:char_limit]\n",
    "    if len(text)>char_limit:\n",
    "        truncated_text = \"{}...\".format(truncated_text)\n",
    "    return(truncated_text)\n",
    "\n",
    "\n",
    "def truncate_list(list_, item_limit):\n",
    "    truncated_list = list_[:item_limit]\n",
    "    return(truncated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916a5993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Make the full size json object and save to file.\n",
    "path = \"../final/data/genes_texts_annotations.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df.fillna(\"\")\n",
    "json_data = to_json(df)\n",
    "json_path = \"../final/data/genes_texts_annotations.json\"\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "# Create a sample version of the file by truncating some of the strings and lists.\n",
    "json_data = to_json(df)\n",
    "json_path = \"../final/samples/genes_texts_annotations.json\"\n",
    "\n",
    "# Subset both the number of entries in the dataset and truncate information in each field.\n",
    "list_limit = 4\n",
    "char_limit = 100\n",
    "num_genes = 100\n",
    "json_data = json_data[:num_genes]\n",
    "for gene in json_data:\n",
    "    gene[\"unique_gene_identifiers\"] = truncate_list(gene[\"unique_gene_identifiers\"], list_limit)\n",
    "    gene[\"other_gene_identifiers\"] = truncate_list(gene[\"other_gene_identifiers\"], list_limit)\n",
    "    gene[\"gene_models\"] = truncate_list(gene[\"gene_models\"], list_limit)\n",
    "    gene[\"text_unprocessed\"] = truncate_string(gene[\"text_unprocessed\"], char_limit)\n",
    "    gene[\"text_tokenized_sents\"] = truncate_string(gene[\"text_tokenized_sents\"], char_limit)\n",
    "    gene[\"text_tokenized_words\"] = truncate_string(gene[\"text_tokenized_words\"], char_limit)\n",
    "    gene[\"text_tokenized_stems\"] = truncate_string(gene[\"text_tokenized_stems\"], char_limit)\n",
    "    gene[\"annotations\"] = truncate_list(gene[\"annotations\"], list_limit)\n",
    "    gene[\"annotations_nc\"] = truncate_list(gene[\"annotations_nc\"], list_limit)\n",
    "\n",
    "# This is an inelegant solution to formatting the json string the way we want to for the small sample file.\n",
    "# Highly dependent on what structure of the dictinoary is, will break if that is changed.\n",
    "indent_size = 4\n",
    "s = json.dumps(json_data, indent=indent_size)\n",
    "s = re.sub(r'\": \\[\\s+', '\": [', s)\n",
    "s = re.sub(r'\",\\s+', '\", ', s)\n",
    "s = re.sub(r'\"\\s+\\]', '\"]', s)\n",
    "\n",
    "\n",
    "# These are necessary because the above inelegant part misses newlines following str:str relationships in the json file.\n",
    "s = s.replace(' \"species_name\":', '\\n{}\"species_name\":'.format(\" \"*(indent_size*2)))\n",
    "s = s.replace(' \"annotations\":', '\\n{}\"annotations\":'.format(\" \"*(indent_size*2)))\n",
    "s = s.replace(' \"text_tokenized_sents\":', '\\n{}\"text_tokenized_sents\":'.format(\" \"*(indent_size*2)))\n",
    "s = s.replace(' \"text_tokenized_words\":', '\\n{}\"text_tokenized_words\":'.format(\" \"*(indent_size*2)))\n",
    "s = s.replace(' \"text_tokenized_stems\":', '\\n{}\"text_tokenized_stems\":'.format(\" \"*(indent_size*2)))\n",
    "s = s.replace(' \"reference_file\":', '\\n{}\"reference_file\":'.format(\" \"*(indent_size*2)))\n",
    "s = s.replace(' \"reference_link\":', '\\n{}\"reference_link\":'.format(\" \"*(indent_size*2)))\n",
    "s = s.replace(' \"unique_gene_identifiers\":', '\\n{}\"unique_gene_identifiers\":'.format(\" \"*(indent_size*2)))\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    f.write(s)\n",
    "\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
